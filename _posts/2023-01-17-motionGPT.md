---
title: "T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete Representations"
collection: publications
permalink: /publication/motionGPT
excerpt: 'TODO.'
date: 2023-01-17
year: 2023
venue: 'ArXiv'
arxiv: 2301.06052
arxiv_url: https://arxiv.org/abs/2211.12194
code: https://github.com/Mael-zys/T2M-GPT
project: https://mael-zys.github.io/T2M-GPT/
demo: https://colab.research.google.com/drive/1Vy69w2q2d-Hg19F-KibqG0FRdpSj3L4O?usp=sharing
teaser: ./images/t2m.gif
authors: Jianrong Zhang ğŸ§‘â€ğŸ’», Yangsong Zhang ğŸ§‘â€ğŸ’», <b>Xiaodong Cun</b>, <a href='https://scholar.google.com/citations?user=o31BPFsAAAAJ&hl=en'>Shaoli Huang</a>, <a href='https://yzhang2016.github.io/'>Yong Zhang</a>, Hongwei Zhao, Hongtao Lu, <a href='https://xishen0220.github.io/'>Xi Shen ğŸ“®</a>
publication: Computer Vision and Pattern Recognition (<b>CVPR</b>)
---

<!-- This paper is about the number 3. The number 4 is left for future work. -->

<!-- [Download paper here](http://academicpages.github.io/files/paper3.pdf) -->
